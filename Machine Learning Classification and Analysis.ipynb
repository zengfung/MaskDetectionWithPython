{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of Images with Masks using Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set from https://www.kaggle.com/rakshana0802/face-mask-detection-data consists of a total of 3833 images (1915 images of people wearing face masks, and 1918 images of people without face masks). The goal of this project is to train sufficient data with various machine learning algorithms and analyze/compare the accuracy and efficiency of each classification method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "The first problem that I faced was that the images in the data set came in different sizes (some larger than others), file types (.PNG, .JPG, .JPEG), modes (images come in P, RGB, and RGBA modes). The difference in file types and modes is especially prevalent among images of people with face masks. Hence, I wrote a program `img2vec.py` that transforms all images to a standard size (128 $\\times$ 128), file type, and mode. The so-called \"standard\" can be easily changed at the top of the program in `img2vec.py`. The output of this data is a `mask.csv` file, where the first column in the file corresponds to the class of each image (with or without mask) and the rest of the columns corresponds to the pixel value in a specific row/column of the transformed images.\n",
    "\n",
    "Note that I have also written the program `vec2img.py` that allows the viewing of the transformed images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increasing the Number of Data\n",
    "\n",
    "One of the issues I faced in the project is the slight lack of data. The reasons are as follows:\n",
    "\n",
    "1. In order for the classifiers to produce a better generalization in classifying the data, more training data has to be provided. This would mean that I will have to sacrifice the number of testing data. \n",
    "\n",
    "2. Similarly, the reverse is also true, that using more of the data as test data would mean sacrificing the number of training data. I would like to see how my classifiers fare in general, and having a small testing data set can lead to higher than normal accuracies.\n",
    "\n",
    "3. In certain classification methods (eg. Neural Network), I would like to use some validation data while training my model. This further reduces my training/testing data set.\n",
    "\n",
    "   In order to solve the above issues, I increased the number of data by  \n",
    "   \n",
    " * using the transformed version of the original images\n",
    " * horizontally flipping each of the transformed image (mirror images)  \n",
    " * flipping each of the transformed images (upside down images)  \n",
    " * horizontally flipping each of the upside down images (mirror of upside down images)  \n",
    " * rotating the transformed version of the original images to the right (right rotated images)\n",
    " * flipping each right rotated images (upside down of right rotated images)  \n",
    " * rotating the transformed version of the original images to the left (left rotated images)  \n",
    " * flipping each left rotated images (upside down of left roated images) \n",
    "\n",
    " This way, I now have 8 times the number of data as compared to my original data set. I then convert both images into matrices of its respective pixel values before adding them into the data frame which is later sent to `mask.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Algorithms Used:\n",
    "\n",
    "* Support Vector Machines\n",
    "\n",
    "* Classification via Singular Value Decomposition (SVD) Properties\n",
    "\n",
    "* Logistic Regression\n",
    "\n",
    "* Linear Discriminant Analysis (LDA)\n",
    "\n",
    "* Random Forest/Decision Trees\n",
    "\n",
    "* Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to import `mask.csv` into a dataframe and sort into training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERCENTAGE_OF_TRAIN = 0.8\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import math as m\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import mask.csv\n",
    "full_data = pd.read_csv('mask.csv', header = 0)\n",
    "\n",
    "# split into two separate data frames by images with and without masks\n",
    "with_mask = full_data[full_data.with_mask == 'Yes']\n",
    "without_mask = full_data[full_data.with_mask == 'No']\n",
    "\n",
    "(train_x_withmask, test_x_withmask, train_y_withmask, test_y_withmask) = train_test_split(with_mask.iloc[:,1:], with_mask.iloc[:,0], train_size = 0.8, test_size = 0.2, random_state = 1)\n",
    "(train_x_withoutmask, test_x_withoutmask, train_y_withoutmask, test_y_withoutmask) = train_test_split(without_mask.iloc[:,1:], without_mask.iloc[:,0], train_size = 0.8, test_size = 0.2, random_state = 1)\n",
    "\n",
    "train_x = np.vstack((train_x_withmask, train_x_withoutmask))\n",
    "train_y = pd.concat([train_y_withmask, train_y_withoutmask], axis = 0).reset_index(drop = True)\n",
    "train_y = np.array(train_y)\n",
    "\n",
    "test_x = np.vstack((test_x_withmask, test_x_withoutmask))\n",
    "test_y_true = pd.concat([test_y_withmask, test_y_withoutmask], axis = 0).reset_index(drop = True)\n",
    "test_y_true = np.array(test_y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del unneeded variables to save space\n",
    "del full_data\n",
    "del with_mask\n",
    "del without_mask\n",
    "del train_x_withmask\n",
    "del train_y_withmask\n",
    "del test_x_withmask\n",
    "del test_y_withmask\n",
    "del train_x_withoutmask\n",
    "del train_y_withoutmask\n",
    "del test_x_withoutmask\n",
    "del test_y_withoutmask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to plot confusion matrices later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "def plot_confmat(clf, X, y):\n",
    "    (fig, (ax1, ax2)) = plt.subplots(1,2, figsize=(10, 5))\n",
    "    disp1 = plot_confusion_matrix(clf, X, y, display_labels = ['Yes', 'No'], \n",
    "                                  cmap = plt.cm.Blues, normalize = None, ax = ax1)\n",
    "    disp2 = plot_confusion_matrix(clf, X, y, display_labels = ['Yes', 'No'], \n",
    "                                  cmap = plt.cm.Blues, normalize = 'true', ax = ax2)\n",
    "    disp1.ax_.set_title('Non-normalized Confusion Matrix')\n",
    "    disp2.ax_.set_title('Normalized Confusion Matrix')\n",
    "    disp2.im_.set_clim(0,1)\n",
    "    return disp1.confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to analyze classification result later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_result = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general idea of how a Support Vector Machine works is that an $n-1$ dimension hyperplane is \"drawn\" on an $n$ dimension \"plot\" to split the data into two (or more) classes. It is constructed such that the distance between each data point and the hyperplane is at its furthest. The hyperplane can be expressed as the following equation:\n",
    "$$w^T x + b = 0$$\n",
    "where $w \\in \\mathbb{R}^{n-1}$ and $b \\in \\mathbb{R}$. The data points with parameter values $x_i$ where $w^T x_i + b < 0$ will be classified into one class and the data points that give us $w^T x_i + b > 0$ will be classified into the other class. Running the SVM when our data points are linearly separable (ie. data points can be classified by drawing a straight hyperplane) is extremely simple. Problems arise when data points aren't linearly separable, which is the case for most classification problems.\n",
    "\n",
    "The simple solution when the data points are not linearly separable is to simply increase the dimensions of the data set to a point where our data is linearly separable. However, this simple solution can be very time and energy consuming, especially when we have more than 10,000 parameters in this case. To tackle this problem, we can use what is called \"kernel tricks\".\n",
    "\n",
    "By definition, \"a function that takes as inputs vectors in the original space and returns the dot product of the vectors in the feature space is called a kernel function\". In other words, if we have $x,z \\in X$ and the map $\\phi: x \\rightarrow \\mathbb{R}^N$ then \n",
    "$$k(x,z) = \\langle \\phi(x), \\phi(z) \\rangle$$\n",
    "is a kernel function. (The Kernel Trick in Support Vector Classification, Towards Data Science)\n",
    "\n",
    "The above definition and function will be the key to solving non-linear classification problems. \n",
    "\n",
    "Note that the solution of the dual problem can is always in the following form (refer to Aarti Singh's slides for better explanation):\n",
    "$$w^* = \\sum_{i = 1}^{N} \\alpha_i y_i x_i$$\n",
    "where $N$ is the number of data points used to run the SVM and $y_i$ is the class (either 1 or -1) of data $i$. Recall the hyperplane equation that was previously mentioned, we have now found the solution $w^*$ that gives us the separation hyperplane for the SVM classification. Substituting $w^*$ into the hyperplane equation, we get \n",
    "$$\\sum_{i = 1}^{N} \\alpha_i y_i (x_i^T x) + b$$\n",
    "\n",
    "Now, we can make predictions with the above equation. Just like before, if $\\sum_{i = 1}^{N} \\alpha_i y_i (x_i^T x) + b > 0$, we will assign it to one of the class, and if $\\sum_{i = 1}^{N} \\alpha_i y_i (x_i^T x) + b < 0$ we will assign it to the other. Here is where the kernel trick comes into play. We want to map the input vectors $x_i$ and $x$ into a feature space, and we can do so by making the following tweak into the equation:\n",
    "$$\\sum_{i = 1}^{N} \\alpha_i y_i (\\phi(x_i)^T \\phi(x)) + b$$\n",
    "\n",
    "This then gives us\n",
    "$$\\sum_{i = 1}^{N} \\alpha_i y_i \\langle \\phi(x_i), \\phi(x)\\rangle + b \\text{ or } \\sum_{i = 1}^{N} \\alpha_i y_i k(x_i, x) + b$$\n",
    "\n",
    "The same classification decision is done to predict the classes of each test data. \n",
    "\n",
    "The next question that generally arises is: What is $k(x,z)$ or $\\phi (x)$? This will be answered in each of the following subsections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this simple case, $k(x,z) = x^T z$, which is equivalent to not using a kernel trick.\n",
    "\n",
    "The code below is used to run SVM with a linear kernel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "classifier1 = SVC(kernel = 'linear', C = 1)\n",
    "classifier1.fit(train_x, train_y)\n",
    "[[tp, fn], [fp, tn]] = plot_confmat(classifier1, test_x, test_y_true)\n",
    "end = time.time()\n",
    "time_taken = end - start\n",
    "\n",
    "classification_result['SVM - Linear'] = {'Time' : time_taken,\n",
    "                                      'True Positive' : tp,\n",
    "                                      'True Negative' : tn,\n",
    "                                      'False Positive' : fp,\n",
    "                                      'False Negative' : fn}\n",
    "\n",
    "print('Time taken:', round(time_taken,2), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete variables to allocate memory\n",
    "del classifier1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "\n",
    "The change in the regularization parameter `C` does not change the results at all. However, there are slight differences in the time taken to complete the classification tasks. \n",
    "\n",
    "On the other hand, it seems that standardizing the variables (pixels of images in this case) does help improve the true positive rate very slightly, but the overall error rate has increased as well. Hence, standardizing the variables in this case is not a good option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBF Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, $k(x,z) = \\exp (- \\gamma ||x - z||^2)$, where $\\gamma > 0$.\n",
    "\n",
    "The code below is used to run SVM with an RBF kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "classifier2 = SVC(kernel = 'rbf', cache_size = 500, C = 10)\n",
    "classifier2.fit(train_x, train_y)\n",
    "[[tp, fn], [fp, tn]] = plot_confmat(classifier2, test_x, test_y_true)\n",
    "end = time.time()\n",
    "time_taken = end - start\n",
    "\n",
    "classification_result['SVM - RBF'] = {'Time' : time_taken,\n",
    "                                      'True Positive' : tp,\n",
    "                                      'True Negative' : tn,\n",
    "                                      'False Positive' : fp,\n",
    "                                      'False Negative' : fn}\n",
    "\n",
    "print('Time taken:', round(time_taken,2), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete variables to allocate memory\n",
    "del classifier2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "\n",
    "The change in the regularization parameter `C` in this case results in a more significant difference. In this case, setting `C = 10` produces the best results. However, the time taken to produce such results is still quite long."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Kernel Degree 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next two cases, we have $k(x,z) = (x^T z + c)^d$ to be our kernel function, where $c$ is a constant that can be added, and $d$ is degree of the polynomial. In this current case, $d = 2$, while the next case is set to be $d = 3$.\n",
    "\n",
    "The code below is used to run SVM with a polynomial kernel of degree 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "classifier3 = SVC(kernel = 'poly', degree = 2)\n",
    "classifier3.fit(train_x, train_y)\n",
    "[[tp, fn], [fp, tn]] = plot_confmat(classifier3, test_x, test_y_true)\n",
    "end = time.time()\n",
    "time_taken = end - start\n",
    "\n",
    "classification_result['SVM - Degree 2'] = {'Time' : time_taken,\n",
    "                                      'True Positive' : tp,\n",
    "                                      'True Negative' : tn,\n",
    "                                      'False Positive' : fp,\n",
    "                                      'False Negative' : fn}\n",
    "\n",
    "print('Time taken:', round(time_taken,2), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete variables to allocate memory\n",
    "del classifier3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Kernel Degree 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is used to run SVM with a polynomial kernel of degree 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "classifier4 = SVC(kernel = 'poly', degree = 3, cache_size = 500)\n",
    "classifier4.fit(train_x, train_y)\n",
    "[[tp, fn], [fp, tn]] = plot_confmat(classifier4, test_x, test_y_true)\n",
    "end = time.time()\n",
    "time_taken = end - start\n",
    "\n",
    "classification_result['SVM - Degree 3'] = {'Time' : time_taken,\n",
    "                                      'True Positive' : tp,\n",
    "                                      'True Negative' : tn,\n",
    "                                      'False Positive' : fp,\n",
    "                                      'False Negative' : fn}\n",
    "\n",
    "print('Time taken:', round(time_taken,2), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete variables to allocate memory\n",
    "del classifier4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "\n",
    "Running the SVM classifier with a polynomial kernel is significantly faster that the rest of the SVM kernels. Additionally, the error rate produced is not too bad either (slightly larger that that of the RBF kernel). The polynomial kernel of degree 2 can be chosen if the importance of speed outweights the importance of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, $k(x,z) = \\tanh(\\alpha x^T z + c)$.\n",
    "\n",
    "The code below isused to run SVM with a sigmoid kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "start = time.time()\n",
    "classifier5 = make_pipeline(StandardScaler(), SVC(kernel = 'sigmoid'))\n",
    "classifier5.fit(train_x, train_y)\n",
    "[[tp, fn], [fp, tn]] = plot_confmat(classifier5, test_x, test_y_true)\n",
    "end = time.time()\n",
    "time_taken = end - start\n",
    "\n",
    "classification_result['SVM - Sigmoid'] = {'Time' : time_taken,\n",
    "                                      'True Positive' : tp,\n",
    "                                      'True Negative' : tn,\n",
    "                                      'False Positive' : fp,\n",
    "                                      'False Negative' : fn}\n",
    "\n",
    "print('Time taken:', round(time_taken,2), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete variables to allocate memory\n",
    "del classifier5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "\n",
    "The SVM classifier fares worst with the sigmoid kernel. Its accuracy is far lower than when using any of the other SVM kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification via Singular Value Decomposition properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now move on to classifying the images via properties of SVD. \n",
    "\n",
    "The function below is used to separate the training data into two matrices, one for images of class 'Yes' and the other for images of class 'No'. Then, the function returns the SVD matrices of each class matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sc\n",
    "\n",
    "def classify_svd_training(train_mat, train_class):\n",
    "    X = train_mat.T\n",
    "    y = train_class.T\n",
    "    \n",
    "    U = [[], []]\n",
    "    S = [[], []]\n",
    "    V = [[], []]\n",
    "    for i, class_val in enumerate(['Yes', 'No']):\n",
    "        index = (y == class_val)\n",
    "        matrix = X[:, index]\n",
    "        (U[i], S[i], V[i]) = sc.linalg.svd(matrix, full_matrices = False)\n",
    "    return (U, S, V)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below used to classify our test data runs the following:\n",
    "\n",
    "1) We take a test data point and convert it into a vector. Let's call this the vector $b$.\n",
    "\n",
    "2) After performing SVD on the training data set in the previous section, we get the following:\n",
    "\n",
    "$$A_i = U_i \\Sigma_i V_i^T$$\n",
    "\n",
    "* $A_i$ is the $m \\times n$ training data matrix of class $i$ ($m$ represents the number of pixels in the image and $n$ represents the number of training data). Note that the value of $m$ is constant for all images since we have already transformed each image to a standard size. \n",
    "\n",
    "* $U_i$ is an $m \\times r$ matrix where each column is orthonormal to one another.\n",
    "\n",
    "* $\\Sigma_i$ is an $r \\times r$ matrix where the diagonals are singular values of $A_i$. The singular values in $\\Sigma_i$ is ordered in descending order in the diagonals of the matrix.\n",
    "\n",
    "* $V_i$ is an $n \\times r$ matrix where each column is orthonormal to one another.\n",
    "\n",
    "Now, we can think of the SVD of $A_i$ as organizing the data in the matrix $A_i$ in the sense that the most important components of $A_i$ (or the important details of images of class $i$) are arranged in the first few columns of $U_i, \\Sigma_i, V_i$. On the other hand, the least important components of $A_i$ (or the white noises in the images of class $i$) are arranged in the last few columns of $U_i, \\Sigma_i, V_i$. \n",
    "\n",
    "With this in mind, we want to select $k$ columns of data from $U_i$ to perform our classification. Let's call this version of $U_i$ with only $k$ columns as $U'_i$. We now want to find the vector $x$ such that \n",
    "\n",
    "$$U'_i x = b$$\n",
    "\n",
    "However, since $U'_i$ is not invertible, we get $x$ by solving the normal equation\n",
    "\n",
    "$$({U'_i}^T U'_i) x = {U'_i}^T b$$\n",
    "\n",
    "After we manage to obtain $x$, we want to find the norm of the residual vector $r_i = b - U'_i x$.\n",
    "\n",
    "3) Assuming we ran part (2) with the training matrix for the class 'Yes', run part (2) again with the training matrix for the class 'No' (or vice versa). We should now have the norms of both residual vectors $r_i$. Compare the norms and classify the test data point to the class with the smaller residual norm. Ie. if $||r_{Yes}|| < ||r_{No}||$ then we classify the test data point into the class 'Yes'.\n",
    "\n",
    "4) Repeat the steps in parts (1) to (3) for each of the test data points. We now have our set of predictions and can compare them with their actual classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_test(test_mat, n, U):\n",
    "    X = test_mat.T\n",
    "    test_size = X.shape[1]\n",
    "    classification = []\n",
    "    for i in range(test_size):\n",
    "        b = X[:, i]\n",
    "        resnorm = np.empty(2)\n",
    "        for j in range(2):\n",
    "            A = U[j][:,:n]\n",
    "            x = np.linalg.inv(A.T @ A) @ A.T @ b\n",
    "            res = b - A @ x\n",
    "            resnorm[j] = np.linalg.norm(res, 2) / np.linalg.norm(b, 2)\n",
    "        if resnorm[0] < resnorm[1]:\n",
    "            classification.append('Yes')\n",
    "        else:\n",
    "            classification.append('No')\n",
    "    return classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is used to find the SVD of both class matrices.\n",
    "\n",
    "Note that in the following code, we split our training data into two: training (80\\%) and validation (20\\%) data. The reason for doing this is because we will be experimenting with different number of singular values to classify the images. In doing so we will need to know the classification accuracies of the \"test\" data and the corresponding number of singular values used. The number of singular values ($k$) that produces the best classification predictions will then be used to predict the real test data. This way, we know for sure that $k$ singular values will definitely produce some of the best possible predictions on the test data. \n",
    "\n",
    "Conversely, if we were to not have a validation data set, and find our best value $k$ based solely on testing with the real test data, it is hard to ensure that that value of $k$ produces the best possible generalized predictions instead of coincidently obtaining a high accuracy value (especially in the case where the accuracy vs $k$-singular values graph fluctuates a lot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# splitting train data into train + validation data\n",
    "(svd_train_x, svd_val_x, svd_train_y, svd_val_y) = train_test_split(train_x, train_y, train_size = 0.8, test_size = 0.2, random_state = 1)\n",
    "\n",
    "start = time.time()\n",
    "(train_U, train_S, train_V) = classify_svd_training(svd_train_x, svd_train_y)\n",
    "end = time.time()\n",
    "time_taken = end - start\n",
    "svd_train_time = time_taken\n",
    "\n",
    "print('Time taken:', round(time_taken, 2), 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Magnitude of Singular Values of both classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following figures are plotted to give us an idea of the range of values of $k$ we should use to form $U'_i$. Recall that choosing a $k$ too small means that we miss out on important components of the training images and can negatively impact classification accuracy. Similarly, selecting a $k$ too large means that we include unnecessary components and white noise of the training images into our classifications, which can lower our predictive accuracy as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3, figsize = (15, 5))\n",
    "\n",
    "x1 = list(range(1,len(train_S[0])+1))\n",
    "y1 = train_S[0]\n",
    "ax[0].plot(x1, y1, label = 'Yes')\n",
    "\n",
    "x2 = list(range(1, len(train_S[1])+1))\n",
    "y2 = train_S[1]\n",
    "ax[0].plot(x2, y2, label = 'No')\n",
    "\n",
    "ax[0].set_xlabel('k-th Singular Value')\n",
    "ax[0].set_ylabel('s')\n",
    "ax[0].title.set_text('Original Values (s)')\n",
    "ax[0].legend()\n",
    "\n",
    "x1 = list(range(1,len(train_S[0])+1))\n",
    "y1 = np.log(train_S[0])\n",
    "ax[1].plot(x1, y1, label = 'Yes')\n",
    "\n",
    "x2 = list(range(1, len(train_S[1])+1))\n",
    "y2 = np.log(train_S[1])\n",
    "ax[1].plot(x2, y2, label = 'No')\n",
    "\n",
    "ax[1].set_xlabel('k-th Singular Value')\n",
    "ax[1].set_ylabel('log(s)')\n",
    "ax[1].title.set_text('Log Transformed Values (log(s))')\n",
    "ax[1].legend()\n",
    "\n",
    "x1 = list(range(1,151))\n",
    "y1 = np.log(train_S[0][:150])\n",
    "ax[2].plot(x1, y1, label = 'Yes')\n",
    "\n",
    "x2 = list(range(1, 151))\n",
    "y2 = np.log(train_S[1][:150])\n",
    "ax[2].plot(x2, y2, label = 'No')\n",
    "\n",
    "ax[2].set_xlabel('k-th Singular Value')\n",
    "ax[2].set_ylabel('log(s)')\n",
    "ax[2].title.set_text('Log Transformed First 150 Values (log(s))')\n",
    "ax[2].legend()\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the first figure above, the change in magnitude of the singular values is so large that it is hard to tell which value of $k$ we should choose. \n",
    "\n",
    "We then proceeded to take the natural log of each singular value and plot the same figure. The results (shown in the middle figure) shows that there is a sharp dip at around 2700. This means that the singular values occurring after 2700 all correspond to white noises. Additionally, we also see a huge change in the magnitudes of singular values at around 200. \n",
    "\n",
    "This brings us to the last figure on the right. In this case, we can see that there is no straightforward way to tell which exact value of $k$ to choose. Hence, I have decided to run the predictions with $k = 5, 10, 15, \\ldots, 600$ below and plot a figure of accuracy vs prediction time based on the different values of $k$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_taken = []\n",
    "accuracy = []\n",
    "n = list(range(5,601,5))\n",
    "\n",
    "for i in n:\n",
    "    start = time.time()\n",
    "    val_y_pred = classify_test(svd_val_x, i, train_U)\n",
    "    end = time.time()\n",
    "    time_taken.append(round(end - start, 2))\n",
    "    confmat = confusion_matrix(svd_val_y, val_y_pred, labels = ['Yes', 'No'])\n",
    "    acc = (confmat[0][0] + confmat[1][1]) / np.sum(confmat)\n",
    "    accuracy.append(acc)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize = (15,5))\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('k')\n",
    "ax1.set_ylabel('Time taken', color=color)\n",
    "ax1.plot(n, time_taken, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Accuracy', color=color)  # we already handled the x-label with ax1\n",
    "ax2.plot(n, accuracy, color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "ax2.set_ylim([0.7,1])\n",
    "\n",
    "fig.suptitle('Time taken vs Accuracyof Validation Data based on k', y = 1)\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the figure above, the time taken to predict increases exponentially as the value of $k$ increases. This is accompanied by slight increase or decrease in accuracy. In this case, we can say that when $k = 545$, we have our most accurate prediction using this classification method. However, when $k = 155$, we seem to get a similar result, but at a significantly shorter amount of time.\n",
    "\n",
    "Overall, if we do not have the luxury to run the above code to find the accuracy of each $k$, it is best to just randomly select a $k$-value between 150 and 200 as the prediction accuracies between those values start to stabilize (less fluctuation) and take a relatively short amount of time too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "k_singularval = (accuracy.index(max(accuracy)) + 1) * 5\n",
    "varname = 'SVD - ' + str(k_singularval)\n",
    "\n",
    "start = time.time()\n",
    "test_y_pred = classify_test(test_x, k_singularval, train_U)\n",
    "end = time.time()\n",
    "time_taken = end - start\n",
    "\n",
    "print('Time taken:', round(time_taken,2), 'seconds')\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize = (10,5))\n",
    "\n",
    "for i, normal in enumerate([None, 'true']):\n",
    "    confmat = confusion_matrix(test_y_true, test_y_pred, labels = ['Yes', 'No'], normalize = normal)\n",
    "    disp = ConfusionMatrixDisplay(confmat, display_labels = ['Yes', 'No'])\n",
    "    disp.plot(ax = ax[i], cmap = plt.cm.Blues)\n",
    "    if i == 0:\n",
    "        disp.ax_.set_title('Non-normalized Confusion Matrix')\n",
    "        classification_result[varname] = {'Time' : svd_train_time + time_taken,\n",
    "                                     'True Positive' : confmat[0][0],\n",
    "                                     'True Negative' : confmat[1][1],\n",
    "                                     'False Positive' : confmat[1][0],\n",
    "                                     'False Negative' : confmat[0][1]}\n",
    "    else:\n",
    "        disp.ax_.set_title('Normalized Confusion Matrix')\n",
    "        disp.im_.set_clim(0,1)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_singularval = (accuracy.index(max(accuracy[:40])) + 1) * 5\n",
    "varname = 'SVD - ' + str(k_singularval)\n",
    "\n",
    "start = time.time()\n",
    "test_y_pred = classify_test(test_x, 155, train_U)\n",
    "end = time.time()\n",
    "time_taken = end - start\n",
    "\n",
    "print('Time taken:', round(time_taken,2), 'seconds')\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize = (10,5))\n",
    "\n",
    "for i, normal in enumerate([None, 'true']):\n",
    "    confmat = confusion_matrix(test_y_true, test_y_pred, labels = ['Yes', 'No'], normalize = normal)\n",
    "    disp = ConfusionMatrixDisplay(confmat, display_labels = ['Yes', 'No'])\n",
    "    disp.plot(ax = ax[i], cmap = plt.cm.Blues)\n",
    "    if i == 0:\n",
    "        disp.ax_.set_title('Non-normalized Confusion Matrix')\n",
    "        classification_result['SVD - 155'] = {'Time' : svd_train_time + time_taken,\n",
    "                                     'True Positive' : confmat[0][0],\n",
    "                                     'True Negative' : confmat[1][1],\n",
    "                                     'False Positive' : confmat[1][0],\n",
    "                                     'False Negative' : confmat[0][1]}\n",
    "    else:\n",
    "        disp.ax_.set_title('Normalized Confusion Matrix')\n",
    "        disp.im_.set_clim(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete variables to allocate memory\n",
    "del classify_svd_training\n",
    "del classify_test\n",
    "del train_U\n",
    "del train_S\n",
    "del train_V\n",
    "del time_taken\n",
    "del accuracy\n",
    "del svd_train_x\n",
    "del svd_val_x\n",
    "del svd_train_y\n",
    "del svd_val_y\n",
    "del val_y_pred\n",
    "del fig\n",
    "del ax1\n",
    "del ax2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the start of training a model using logistic regression, my guess would be that its results would be significantly worse than most of the previous methods, simply because of the following:\n",
    "\n",
    "1. Logistic regression is a linear classifier, meaning the training data will be separated by a single straight hyperplane. Its only difference with the linear kernel SVM model is the way the hyperplane is produce. As we can see in the linear kernel SVM section, the classification of testing data took a long time and the resulting accuracy is not really high.\n",
    "\n",
    "2. However, the difference between logistic regression and the linear kernel SVM is that logistic regression classifies data into classes based on their probabilities to be in each class. Additionally, this probability follows a sigmoid function. This means that if a test data has a 0.6 chance that it is in class 'Yes', and 0.4 chance that it is in class 'No', it will be classified into the 'Yes' class. On the other hand, the SVM method produces results that are binary, ie. if the test data is in the 'Yes' region of the hyperplane, it will be classified as 'Yes'. This could end up allowing the logistic regression method to perform slightly better than the linear kernel SVM method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "start = time.time()\n",
    "classifier6 = LogisticRegression(solver = 'saga', penalty = 'l1', C =100, max_iter = 100)\n",
    "classifier6.fit(train_x, train_y)\n",
    "[[tp, fn], [fp, tn]] = plot_confmat(classifier6, test_x, test_y_true)\n",
    "end = time.time()\n",
    "time_taken = end - start\n",
    "\n",
    "print('Time taken:', round(time_taken,2), 'seconds')\n",
    "\n",
    "classification_result['Logistic Reg.'] = {'Time' : time_taken,\n",
    "                                          'True Positive' : tp,\n",
    "                                          'True Negative' : tn,\n",
    "                                          'False Positive' : fp,\n",
    "                                          'False Negative' : fn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete variables to allocate memory\n",
    "del classifier6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "\n",
    "As expected, the results from the classification via Logistic Regression only produces a slightly better result as compared to the SVM with linear kernel. This is the case even after the tuning of paramters `C` and `penalty`. In fact, we always get the warning that `the coef_ did not converge` regardless of how much the `max_iter` parameter was extended. This is probably due to the fact that the data set is not separated linearly, and hence separating the training data itself already produces huge errors even with various parameter tunings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Discriminant Analysis (LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like the Logistic Regression, LDA is also a linear classifier. Hence, it is also expected that this classifier will fare badly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "start = time.time()\n",
    "classifier7 = LinearDiscriminantAnalysis(solver = 'svd')\n",
    "classifier7.fit(train_x, train_y)\n",
    "[[tp, fn], [fp, tn]] = plot_confmat(classifier7, test_x, test_y_true)\n",
    "end = time.time()\n",
    "time_taken = end - start\n",
    "\n",
    "print('Time taken:', round(time_taken,2), 'seconds')\n",
    "\n",
    "classification_result['LDA'] = {'Time' : time_taken,\n",
    "                                'True Positive' : tp,\n",
    "                                'True Negative' : tn,\n",
    "                                'False Positive' : fp,\n",
    "                                'False Negative' : fn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete variables to allocate memory\n",
    "del classifier7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "\n",
    "While I have predicted that the LDA will fare badly compared to most other classifiers I have used previously, it is very unexpected that the overall error rate of LDA is so much worse than that of the Logistic Regression and the linear kernel SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression vs LDA\n",
    "\n",
    "After running the Logistic Regression and LDA classifiers, it is common to wonder why there is such a huge difference in accuracy between the two classifiers.\n",
    "\n",
    "According to several websites (links under the Reference and Resources section), the difference in accuracy is mainly due to the different requirements required by both of these classifiers:\n",
    "\n",
    "* In Logistic Regression, the distributions of the predictors do not matter. On the other hand, LDA assumes that the predictors follow a multivariate normal distribution.\n",
    "\n",
    "* In Logistic Regression, there is no requirement in the predictors' within-group covariance matrices. This is hugely different compared to the LDA, where we assume that the sample predictors' (the training data's predictors in our case) within-group covariance matrices (namely $S_{Yes}$ and $S_{No}$) should be equal to the population predictors' covariance matrix (denoted $\\Sigma$).\n",
    "\n",
    "As we can see in our data, each \"feature\" or \"predictor\" actually represents the pixel values of each pixel, which means that they are very likely not normally distributed, nor do they have covariances equal to a \"population\" covariance. I believe that it is due to the restrictions of the LDA classifier and the failure of the predictor variables to meet the restrictions, LDA does not perform as well as the Logistic Regression in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random Forest Classification method is basically done by running Decision Tree Classification methods multiple times with slight tuning in data and features used. So before we dive straight into Random Forest Classification, let's first train our training data with a Decision Tree Classifier.\n",
    "\n",
    "The general idea of running a Decision Tree Classifier is simple:\n",
    "\n",
    "1. We have $m$ training data with $n$ features. In our case, this translates to our 3449 rows of training data and 65,536 features (pixels).\n",
    "\n",
    "2. We start off at a root node with all our training data. Then, a feature is selected to split the training data into two. Eg. we start with the pixel (1,1) in each image. Images with pixel (1,1) values more than $\\alpha$ will be transferred to a new node at the right side of the root node, and the rest will be transferred to a new node at the left side of the root node.\n",
    "\n",
    "3. As of right now, we have transferred all of our training data into nodes that are either at the left or right nodes of the root node. Now, we want to check if any of the nodes contain only a single class, ie. the node contains images that are all of class 'Yes' or all of class 'No'. If this is the case, we are done with this node, no further action is needed to work on this node. Otherwise, we will need to repeat the process of step 2, this time selecting a different feature to classify our training data. Note that in every classification step, we are not allowed to transfer our data into a used node (ie. it has to be a new node every step).\n",
    "\n",
    "4. After running steps 2 and 3 multiple times, we will arrive at a point where each and every non-empty nodes contain only a single class. At this point, we are done.\n",
    "\n",
    "Note that the Decision Tree Classification method has the following problems:\n",
    "\n",
    "* The time taken can be quite long depending on the data set, or the chosen training data. This is due to the fact that the \"learning of optimal decision tree is NP-complete\" (Wikipedia). This can be observed even when running the classification method on this data set, where the time taken to train the model and classify the testing data can go as fast as less than 2 minutes, to being as slow as more than 2 hours.\n",
    "\n",
    "* Decision Trees tend to overfit. Recall that we will keep transferring data into new nodes until each node contains only one class of data. This becomes a problem when we put our test data into the decision tree since the properties of our test data is not exactly the same as those of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "start = time.time()\n",
    "classifier8 = DecisionTreeClassifier(criterion = 'gini')\n",
    "classifier8.fit(train_x, train_y)\n",
    "[[tp, fn], [fp, tn]] = plot_confmat(classifier8, test_x, test_y_true)\n",
    "end = time.time()\n",
    "time_taken = end - start\n",
    "\n",
    "print('Time taken:', round(time_taken,2), 'seconds')\n",
    "\n",
    "classification_result['Decision Tree'] = {'Time' : time_taken,\n",
    "                                'True Positive' : tp,\n",
    "                                'True Negative' : tn,\n",
    "                                'False Positive' : fp,\n",
    "                                'False Negative' : fn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete variables to allocate memory\n",
    "del classifier8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the Decision Tree Classifier above, we have the following findings:\n",
    "\n",
    "* The time taken for this to run is actually quite short. The only other classifier with such short time taken so far is the classifier that utilizes SVD properties.\n",
    "\n",
    "* The results of this test is also very accurate. This is due to the fact that this classifier does not apply to strictly linear data, unlike the linear kernel SVM, Logistic Regression, and LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have tried out the Decision Tree Classifier, we move on to the Random Forest Classifier. The Random Forest Classifier is different from the Decision Tree Classifer in the following ways:\n",
    "\n",
    "* Instead of using all features to classify our training data, the features used is selected at random.\n",
    "\n",
    "* Instead of using all of our training data for classification, the training data is selected at random with replacement (aka bootstrapping). This means that there is a chance that we might select the same exact data (although it is less likely if the size of data is huge).\n",
    "\n",
    "Now, with our new randomly selected subset of training data with randomly selected features, we run the Decision Tree Classifier once again. \n",
    "\n",
    "This time, however, we will be running all the above for a number of times (note the parameter `n_estimators` in the code below) before concluding with a model that is an average of all the models we got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "start = time.time()\n",
    "classifier9 = RandomForestClassifier(n_estimators = 100, criterion = 'gini')\n",
    "classifier9.fit(train_x, train_y)\n",
    "[[tp, fn], [fp, tn]] = plot_confmat(classifier9, test_x, test_y_true)\n",
    "end = time.time()\n",
    "time_taken = end - start\n",
    "\n",
    "print('Time taken:', round(time_taken,2), 'seconds')\n",
    "\n",
    "classification_result['Random Forest'] = {'Time' : time_taken,\n",
    "                                'True Positive' : tp,\n",
    "                                'True Negative' : tn,\n",
    "                                'False Positive' : fp,\n",
    "                                'False Negative' : fn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete variables to allocate memory\n",
    "del classifier9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "\n",
    "After running the Random Forest Classifier, the results that was obtained was very unexpected... in a good way. This classification method has given us one of the highest accuracy rate among all the methods we have used so far, and in the shortest amount of time too! \n",
    "\n",
    "A thing to note about the Random Forest Classifier is that, even after playing around with the `n_estimators` parameter with values 100, 200, 1000... The accuracy of the classifiers are highly similar, although the time taken to build the classifiers increases rapidly. Hence, I have decided to use `n_estimators = 100` since it gives us the best accuracy vs time trade-off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is significantly trickier than the others, due to the following reasons:\n",
    "\n",
    "* more parameters to tune\n",
    "\n",
    "* there is an infinite amount of different types of Neural Network architecture. Other than the neurons in the input and output layers being fixed, there is an infinite number of hidden layer and neuron count architectures. A lot of experimentation has to be done regarding the number of hidden layers and neurons to be used in our model.\n",
    "\n",
    "Due to these reasons, the changes in code for each parameter tune will not be repeated here, and will instead be done in a separate file, namely `keras_nn.py`. This file is written by importing the Keras library since it is easy to navigate and make parameter changes.\n",
    "\n",
    "Additionally, for future references, I have also written `tensorflow_nn.py` that does the same exact thing but instead using the tensorflow library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Settings and Values in Training of Neural Network\n",
    "\n",
    "The following are some settings that are set as our default in the training of our Neural Network, and will not be changed unless stated specifically in the section.\n",
    "\n",
    "1. Optimizer: Adam\n",
    "\n",
    "2. Learning Rate: `1e-4`\n",
    "\n",
    "3. Batch Size = 256\n",
    "\n",
    "4. Network Architecture: 16384 $\\rightarrow$ 500 $\\rightarrow$ 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effects of Parameter Tuning\n",
    "\n",
    "In training the best possible Neural Netowrk model, there are certain parameters that needs to be tuned and experimented on. In the following sections, I have experimented the parameters in different ways and observed their effects on cost and accuracy changes in my training and validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Standardization (Transformation) of data and L1/L2 regularization parameters\n",
    "\n",
    " In this section, we want to observe how transforming the data and adding regularization parameters can affect the accuracies of the training, validation and test data.\n",
    "\n",
    " The type of data transformations used here are:\n",
    "\n",
    " 1. No transformation, ie. the same input data from before is used\n",
    "\n",
    " 2. Normalized input, ie. each input neuron value is transformed with the following formula:\n",
    "$$x' = \\frac{x - x_{min}}{x_{max} - x_{min}}$$\n",
    "where $x$ is the initial input value for a particular neuron, and $x_{min}$ and ${x_max}$ are smallest and largest input values for the particular neuron among the entire training data set.\n",
    "\n",
    " 3. Standardized input, ie. each input neuron value is transformed to fit a normal distribution via the following formula:\n",
    "$$x' = \\frac{x - \\mu_x}{\\sigma_x}$$\n",
    "where $x$ is the initial input value for a particular neuron, and $\\mu_x$ and $\\sigma_x$ are the mean and standard deviation respectively for the particular neuron among the entire training data set.\n",
    "\n",
    " As for our L1 and L2 regularization parameters, the reason we want to use them is this:  \n",
    " - We have our cost function which we want to minimize in order to improve our model. In general, the following are some of the types of cost functions:\n",
    " \n",
    "   1. Quadratic cost:  \n",
    "   $$C = \\frac{1}{n} \\sum_{i = 1}^{n}||y_i - y'_i||_2$$\n",
    "      where $y_i$ is the actual value of the responding variable for data point $i$ and $y'_i$ is its corresponding predicted value. This is usually used when we train our Neural Network model for regression purposes and our output layer has only one node.\n",
    "   \n",
    "   2. Cross Entropy cost:  \n",
    "   $$C = \\frac{1}{n} \\sum_{i = 1}^{n} \\sum_{c = 1}^{k} y_{i,c} \\log_e({y'_{i,c})}$$\n",
    "      where $y_{i,c} = \\begin{cases} 1 & \\text{if data point } i \\text{ is in class } c \\\\ 0 & \\text{otherwise} \\end{cases}$ and $y'_{i,c}$ is the predicted probability that the data point $i$ is class $c$. This is usually used when we train our Neural Network model for classification purposes and our output layer has $k$ number of nodes (to classify data points into $k$ classes). Note that in the case of binary classification (2 classes), one can use an output layer with only one node.\n",
    "      \n",
    "   In this analysis, we will be using the cross entropy cost function.\n",
    "   \n",
    " - Now, simply having a cost function might not be enough as it leads to a possible overfitting of the data set. To counter this issue, we add regularization parameter(s) into our cost function. There are 3 (main) types of regularization that we will use in the training of this Neural Network:\n",
    " \n",
    "   1. L1 Regularization\n",
    "      $$L1 = \\lambda_1 \\sum_{j = 1}^{p} |\\beta_j|$$\n",
    "      where $\\beta_j$ represents each weight and bias in the neural network model.\n",
    "      \n",
    "   2. L2 Regularization  \n",
    "      $$L2 = \\lambda_2 \\sum_{j = 1}^{p} \\beta_j^2$$\n",
    "   \n",
    "   3. Dropout/Pruning  \n",
    "      In Neural Network, using a dropout regularization basically means reducing the number of nodes (in the hidden layer) and arcs as we train the model in order for it to better generalize the data set.\n",
    "      \n",
    " - With this in mind, we can now add either the L1 or L2 (or both) regularization into our cost function. The dropout is a different type of regularization method that we will experiment later on. Our new cost function becomes $$C' = C + L1 + L2$$\n",
    "   \n",
    "   We can now experiment around with different $\\lambda_1$ and $\\lambda_2$ values to see which values produce the best model. Note that setting a $\\lambda$ too large can lead to underfitting, whereas setting it too small can lead to overfitting.\n",
    " \n",
    " For our L1 and L2 regularization parameters, we tested each of them with the values `0`, `1e-5`, `1e-4`, `1e-3`, `1e-2`, and `1e-1`, ie:\n",
    " \n",
    " 1. L1 = `0`, L2 = `0`\n",
    " 2. L1 = `0`, L2 = `1e-5`\n",
    " 3. L1 = `0`, L2 = `1e-4`\n",
    " 4. L1 = `0`, L2 = `1e-3`\n",
    " 5. L1 = `0`, L2 = `1e-2`\n",
    " 6. L1 = `0`, L2 = `1e-1`\n",
    " 7. L1 = `1e-5`, L2 = 0\n",
    " 8. ... and so on\n",
    " \n",
    " The code and results are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(NUM_OF_DATA, INPUT_NODES) = train_x.shape\n",
    "OUTPUT_NODES = 2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# convert test and training y values from 'Yes' or 'No' to [1,0] or [0,1] respectively\n",
    "train_y_01 = np.zeros((NUM_OF_DATA,2), dtype = int)\n",
    "for i in range(NUM_OF_DATA):\n",
    "    if train_y[i] == 'Yes':\n",
    "        train_y_01[i][0] = 1\n",
    "    else:\n",
    "        train_y_01[i][1] = 1\n",
    "test_y_01 = np.zeros((len(test_y_true), 2), dtype = int)\n",
    "for i in range(len(test_y_true)):\n",
    "    if test_y_true[i] == 'Yes':\n",
    "        test_y_01[i][0] = 1\n",
    "    else:\n",
    "        test_y_01[i][1] = 1\n",
    "        \n",
    "# splitting training data into train and validation data sets\n",
    "(nn_x_train, nn_x_validation, nn_y_train, nn_y_validation) = train_test_split(train_x, train_y_01, train_size = 0.8, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network architecture (neurons in hidden layer)\n",
    "LAYER1_NODES = 500\n",
    "\n",
    "# Setting epochs, batch size and learning rate\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "# L1 and L2 ragularization parameters to experiment with\n",
    "L1_list = [0, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "L2_list = [0, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.constraints import maxnorm\n",
    "from keras import regularizers #for l1 or l2 regularizers\n",
    "from keras.callbacks import EarlyStopping #stop training when monitored argument stops decreasing/increasing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# prepare dataset with input and output scalers, can be none\n",
    "def transform_dataset(input_scaler, train_X, val_X, test_X):\n",
    "    # scale inputs\n",
    "    if input_scaler is not None:\n",
    "        # fit scaler\n",
    "        input_scaler.fit(train_X)\n",
    "        # transform training dataset\n",
    "        trainX = input_scaler.transform(train_X)\n",
    "        # transform validation dataset\n",
    "        validX = input_scaler.transform(val_X)\n",
    "        # transform test dataset\n",
    "        testX = input_scaler.transform(test_X)\n",
    "        return trainX, validX, testX\n",
    "    else:\n",
    "        return train_X, val_X, test_X\n",
    "\n",
    "# train the Neural Network model    \n",
    "def evaluate_model(train_X, train_y, val_X, val_y, test_X, test_y):\n",
    "    start = time.time()\n",
    "    # define model\n",
    "    model = Sequential([\n",
    "        #input to first hidden layer\n",
    "        Dense(output_dim = LAYER1_NODES, input_dim = INPUT_NODES,\n",
    "              activation = 'relu', kernel_constraint= maxnorm(4),\n",
    "              kernel_regularizer = regularizers.l1_l2(l1 = L1, l2 = L2)\n",
    "              ),\n",
    "                       \n",
    "        #second hidden layer to output\n",
    "        Dense(output_dim = OUTPUT_NODES, input_dim = LAYER1_NODES, activation = 'softmax'),\n",
    "        ])\n",
    "    \n",
    "    # compile model\n",
    "    opt = optimizers.adam(learning_rate = LEARNING_RATE)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])\n",
    "    \n",
    "    # fit model\n",
    "    history = model.fit(train_X, train_y, epochs = EPOCHS, batch_size = BATCH_SIZE, \n",
    "          validation_data = (val_X, val_y), verbose = 0,\n",
    "          # callbacks = [EarlyStopping(monitor='val_accuracy', patience=20)]\n",
    "          ) \n",
    "\n",
    "    # evaluate the model\n",
    "    _, test_acc = model.evaluate(test_X, test_y)\n",
    "    \n",
    "    end = time.time()\n",
    "    time_taken = end - start\n",
    "    \n",
    "    train_cost = history.history['loss']\n",
    "    train_acc = history.history['accuracy']\n",
    "    val_cost = history.history['val_loss']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    return (train_cost, train_acc, val_cost, val_acc, test_acc, time_taken)\n",
    "\n",
    "# transform data and train model\n",
    "def run_model(input_scaler, train_X, train_y, val_X, val_y, test_X, test_y):\n",
    "    # get dataset\n",
    "    trainX, valX, testX = transform_dataset(input_scaler, train_X, val_X, test_X)\n",
    "    result = evaluate_model(trainX, train_y, valX, val_y, testX, test_y)\n",
    "    return result\n",
    "\n",
    "for j, L1 in enumerate(L1_list):\n",
    "    fig1, ax1 = plt.subplots(2,3, figsize = (40,20))\n",
    "    fig2, ax2 = plt.subplots(2,3, figsize = (40,20))\n",
    "    for i, L2 in enumerate(L2_list):\n",
    "        print('Running L1 =',L1, 'L2 =',L2)\n",
    "        (none_train_cost, none_train_acc, none_val_cost, none_val_acc, none_test_acc, _) = run_model(None, nn_x_train, nn_y_train, nn_x_validation, nn_y_validation, test_x, test_y_01)\n",
    "        (minmax_train_cost, minmax_train_acc, minmax_val_cost, minmax_val_acc, minmax_test_acc, _) = run_model(MinMaxScaler(), nn_x_train, nn_y_train, nn_x_validation, nn_y_validation, test_x, test_y_01)\n",
    "        (std_train_cost, std_train_acc, std_val_cost, std_val_acc, std_test_acc, _) = run_model(StandardScaler(), nn_x_train, nn_y_train, nn_x_validation, nn_y_validation, test_x, test_y_01)\n",
    "        \n",
    "        ep = list(range(1,EPOCHS+1))\n",
    "     \n",
    "        # plot cost functions\n",
    "        ax1[i//3, i%3].plot(ep, none_train_cost, 'r:', label = 'None (Train)')\n",
    "        ax1[i//3, i%3].plot(ep, none_val_cost, 'ro-', label = 'None(Val)')\n",
    "        ax1[i//3, i%3].plot(ep, minmax_train_cost, 'b:', label = 'MinMax (Train)')\n",
    "        ax1[i//3, i%3].plot(ep, minmax_val_cost, 'bo-', label = 'MinMax (Val)')\n",
    "        ax1[i//3, i%3].plot(ep, std_train_cost, 'k:', label = 'Std (Train)')\n",
    "        ax1[i//3, i%3].plot(ep, std_val_cost, 'ko-', label = 'Std (Val)')\n",
    "        ax1[i//3, i%3].set_xlabel('EPOCH', fontsize = 20)\n",
    "        ax1[i//3, i%3].set_ylabel('cost', fontsize = 20)\n",
    "        ax1[i//3, i%3].set_title('Change in cost (L1='+str(L1)+',L2='+str(L2)+')', fontsize = 25)\n",
    "        ax1[i//3, i%3].legend(fontsize = 20)\n",
    "        \n",
    "        # plot accuracy functions\n",
    "        ax2[i//3, i%3].plot(ep, none_train_acc, 'r:', label = 'None (Train)')\n",
    "        ax2[i//3, i%3].plot(ep, none_val_acc, 'ro-', label = 'None(Val)')\n",
    "        ax2[i//3, i%3].plot(ep, [none_test_acc]*len(ep), 'r-')\n",
    "        ax2[i//3, i%3].plot(ep, minmax_train_acc, 'b:', label = 'MinMax (Train)')\n",
    "        ax2[i//3, i%3].plot(ep, minmax_val_acc, 'bo-', label = 'MinMax (Val)')\n",
    "        ax2[i//3, i%3].plot(ep, [minmax_test_acc]*len(ep), 'b-')\n",
    "        ax2[i//3, i%3].plot(ep, std_train_acc, 'k:', label = 'Std (Train)')\n",
    "        ax2[i//3, i%3].plot(ep, std_val_acc, 'ko-', label = 'Std (Val)')\n",
    "        ax2[i//3, i%3].plot(ep, [std_test_acc]*len(ep), 'k-')\n",
    "        ax2[i//3, i%3].set_xlabel('EPOCH', fontsize = 20)\n",
    "        ax2[i//3, i%3].set_ylabel('accuracy', fontsize = 20)\n",
    "        ax2[i//3, i%3].set_ylim(0.4, 1)\n",
    "        ax2[i//3, i%3].set_title('Change in accuracy (L1='+str(L1)+',L2='+str(L2)+')', fontsize = 25)\n",
    "        ax2[i//3, i%3].legend(fontsize = 20)\n",
    "    fig1.show()\n",
    "    fig2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete variables that will no longer be used to allocate memory\n",
    "del none_train_cost\n",
    "del none_train_acc\n",
    "del none_val_cost\n",
    "del none_val_acc\n",
    "del none_test_acc\n",
    "del minmax_train_cost\n",
    "del minmax_train_acc\n",
    "del minmax_val_cost\n",
    "del minmax_val_acc\n",
    "del minmax_test_acc\n",
    "del std_train_cost\n",
    "del std_train_acc\n",
    "del std_val_cost\n",
    "del std_val_acc\n",
    "del std_test_acc\n",
    "del fig1\n",
    "del ax1\n",
    "del fig2\n",
    "del ax2\n",
    "del L1_list\n",
    "del L2_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##### Notes:\n",
    " \n",
    " 1. $\\lambda_1$ for the L1 regularization seems to have huge negative effects on the training of the model, especially when we set it with large values such as 0.1 and 0.01. In such cases, regardless of the value of $\\lambda_2$, our resulting models perform very badly. The best cases would be when we were to use the non-transformed original data as input in the training of the models since they produce highly fluctuating predictions of both the training and the validation data. On the other hand, we constantly obtain a prediction accuracy of around 0.5 in both our training and validation data sets if we were to normalize/standardize our data to form our inputs. This shows that the models are not learning at all.\n",
    " \n",
    " 2. Discounting the cases where $\\lambda_1 = 0.1$ or $0.01$, we find that training inputs that are standardized perform best in regards to training a model that produces high training, validation and test accuracies. The models with standardized inputs can often produce training and test accuracies that are 5-10\\% higher than that of the non-transformed original inputs, which produce the worst set of results among all 3 types of models.\n",
    "\n",
    " 3. Similarly, in cases where we have the value of $\\lambda_2$ set too large, we tend to observe a decrease in learning in the Neural Network models. In these cases, while the cost values constantly decreases, there tends to be no change/fluctuations around the a less than optimum accuracies in the training and validation data. The fix to this problem is to decrease the value of $\\lambda_1$ and $\\lambda_2$. \n",
    "\n",
    " 4. The issue that was encountered in parts 2 and 3 is known as underfitting.\n",
    "\n",
    " 5. The best results is obtained when we use only the L2 regularizer and set $\\lambda_2$ = `1e-4` or `1e-5`. There seems to be a lot more fluctuations and lower accuracy values if we have $\\lambda$ go any smaller, although things might change if we also switch out certain other parameters.\n",
    "\n",
    " 6. Regardless of L1 and L2 values used, we find that the models utilizing the original data (not transformed) tend to have significantly higher costs as compared to the normalized and standardized input data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * #### Batch size and Learning Rate\n",
    " \n",
    "   1. In the paper \"Don't Decay the Learning Rate, Increase the Batch Size\" by Smith, Kindermans, Ying and Le, they wrote:  \n",
    "\n",
    "    *** \n",
    " \"When we decay the learning rate, the noise scale falls, enabling us to converge to the minimum of the cost function. However we can achieve the same reduction in noise scale at constant learning rate by increasing the batch size. The main contribution of this work is to show that it is possible to make efficient use of vast training batches, if one increases the batch size during training at constant learning rate until $B \\sim N/10$ (batch size around 1/10 of training data size). After this point, we revert to the use of decaying learning rates.\" \n",
    "    ***   \n",
    "  Therefore, I had to play around with various different batch sizes and learning rates in this section to observe how the model fares with different combinations.\n",
    "  \n",
    "   2. The batch sizes that will be tested are 4, 32, 128, 256, 512, and 1024. The learning rates that will be tested are 0.1, 0.01, 0.001, 0.0001, `1e-5`, and `1e-6`.\n",
    "\n",
    "  The code and results are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYER1_NODES = 500\n",
    "\n",
    "# Setting epochs and L1, L2 regularization parameters\n",
    "EPOCHS = 50\n",
    "L1 = 0\n",
    "L2 = 1e-5\n",
    "\n",
    "\n",
    "batch_size_list = [4, 32, 128, 256, 512, 1024]\n",
    "lr_list = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6]\n",
    "\n",
    "for j, BATCH_SIZE in enumerate(bacth_size_list):\n",
    "    fig1, ax1 = plt.subplots(2,3, figsize = (40,20))\n",
    "    fig2, ax2 = plt.subplots(2,3, figsize = (40,20))\n",
    "    for i, LEARNING_RATE in enumerate(lr_list):\n",
    "        print('Running BS =',BATCH_SIZE, 'LR =',LEARNING_RATE)\n",
    "        (train_cost, train_acc, val_cost, val_acc, test_acc, _) = run_model(StandardScaler(), nn_x_train, nn_y_train, nn_x_validation, nn_y_validation, test_x, test_y_01)\n",
    "        \n",
    "        ep = list(range(1,EPOCHS+1))\n",
    "     \n",
    "        # plot cost functions\n",
    "        ax1[i//3, i%3].plot(ep, train_cost, 'r:', label = 'Train')\n",
    "        ax1[i//3, i%3].plot(ep, val_cost, 'ro-', label = 'Val')\n",
    "        ax1[i//3, i%3].set_xlabel('EPOCH', fontsize = 20)\n",
    "        ax1[i//3, i%3].set_ylabel('cost', fontsize = 20)\n",
    "        ax1[i//3, i%3].set_title('Change in cost (BS='+str(BATCH_SIZE)+', LR='+str(LEARNING_RATE)+')', fontsize = 25)\n",
    "        ax1[i//3, i%3].legend(fontsize = 20)\n",
    "        \n",
    "        # plot accuracy functions\n",
    "        ax2[i//3, i%3].plot(ep, train_acc, 'r:', label = 'Train')\n",
    "        ax2[i//3, i%3].plot(ep, val_acc, 'ro-', label = 'Val')\n",
    "        ax2[i//3, i%3].plot(ep, [test_acc]*len(ep), 'r-')\n",
    "        ax2[i//3, i%3].set_xlabel('EPOCH', fontsize = 20)\n",
    "        ax2[i//3, i%3].set_ylabel('accuracy', fontsize = 20)\n",
    "        ax2[i//3, i%3].set_ylim(0.4, 1)\n",
    "        ax2[i//3, i%3].set_title('Change in accuracy (BS='+str(BATCH_SIZE)+', LR='+str(LEARNING_RATE)+')', fontsize = 25)\n",
    "        ax2[i//3, i%3].legend(fontsize = 20)\n",
    "    fig1.show()\n",
    "    fig2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete variables that will no longer be used to allocate memory\n",
    "del train_cost\n",
    "del train_acc\n",
    "del val_cost\n",
    "del val_acc\n",
    "del test_acc\n",
    "del fig1\n",
    "del ax1\n",
    "del fig2\n",
    "del ax2\n",
    "del evaluate_model\n",
    "del run_model\n",
    "del batch_size_list\n",
    "del lr_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notes:\n",
    "\n",
    "1. Analysis on small batches as compared to large batches:  \n",
    " * Takes a long time to train, since the model has to be updated more times. In particular, the model updates every time we run through a batch. So if we have a training size $N$ and batch size $k$, the model is updated $N/k$ times per epoch.  \n",
    " * The smaller the batch size, the smaller the learning rate that should be used. With a small batch size, it is easier to overshoot in the gradient descent compared to bigger batch sizes.\n",
    " \n",
    "2. Overall, it seems that using a batch size of between 32 and 256, learning rate of about `1e-5` to `1e-4`, and $\\lambda$ of `1e-4` produces the most balanced result in terms of no underfitting/overfitting and highest training/validation/test accuracies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * #### Network Architecture\n",
    " \n",
    "   1. From what we have achieved so far, we seem to be able to train relatively good models. In fact, we have even managed to train some models to the point where we achieve 100\\% training accuracies. However, the corresponding validation accuracies have never broken the 88\\% mark, signalling the issue of overfitting.\n",
    "   \n",
    "   2. Other than incorporating regularization and changing the batch size and learning rate, another thing that could be done to improve the validation accuracy and reduce the overfitting of the model is to change the network architecture.\n",
    "   \n",
    "   3. The network architectures that we will experiment with are:\n",
    "     * 16384 $\\rightarrow$ 2  \n",
    "     * 16384 $\\rightarrow$ 50 $\\rightarrow$ 2  \n",
    "     * 16384 $\\rightarrow$ 500 $\\rightarrow$ 2  \n",
    "     * 16384 $\\rightarrow$ 1000 $\\rightarrow$ 2  \n",
    "     * 16384 $\\rightarrow$ 50 $\\rightarrow$ 50 $\\rightarrow$ 2  \n",
    "     * 16384 $\\rightarrow$ 50 $\\rightarrow$ 1000 $\\rightarrow$ 2  \n",
    "     * 16384 $\\rightarrow$ 500 $\\rightarrow$ 50 $\\rightarrow$ 2  \n",
    "     * 16384 $\\rightarrow$ 500 $\\rightarrow$ 500 $\\rightarrow$ 2  \n",
    "     * 16384 $\\rightarrow$ 500 $\\rightarrow$ 1000 $\\rightarrow$ 2  \n",
    "     * 16384 $\\rightarrow$ 1000 $\\rightarrow$ 50 $\\rightarrow$ 2  \n",
    "     * 16384 $\\rightarrow$ 1000 $\\rightarrow$ 500 $\\rightarrow$ 2  \n",
    "     * 16384 $\\rightarrow$ 1000 $\\rightarrow$ 1000 $\\rightarrow$ 2  \n",
    "     \n",
    "   The code and results are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting epochs, batch size, learning rate and L1, L2 regularization parameters\n",
    "EPOCHS = 50\n",
    "L1 = 0\n",
    "L2 = 1e-5\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "NN_DESIGNS = [(INPUT_NODES, OUTPUT_NODES), # no hidden layer\n",
    "              (INPUT_NODES, 50, OUTPUT_NODES), # 1 hidden layer\n",
    "              (INPUT_NODES, 500, OUTPUT_NODES),\n",
    "              (INPUT_NODES, 1000, OUTPUT_NODES),\n",
    "              (INPUT_NODES, 50, 50, OUTPUT_NODES), # 2 hidden layers\n",
    "              (INPUT_NODES, 50, 1000, OUTPUT_NODES),\n",
    "              (INPUT_NODES, 500, 50, OUTPUT_NODES),\n",
    "              (INPUT_NODES, 500, 500, OUTPUT_NODES),\n",
    "              (INPUT_NODES, 500, 1000, OUTPUT_NODES),\n",
    "              (INPUT_NODES, 1000, 50, OUTPUT_NODES),\n",
    "              (INPUT_NODES, 1000, 500, OUTPUT_NODES),\n",
    "              (INPUT_NODES, 1000, 1000, OUTPUT_NODES)]\n",
    "\n",
    "def evaluate_model(nn_design, train_X, train_y, val_X, val_y, test_X, test_y):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    \n",
    "    layers = len(nn_design)\n",
    "    \n",
    "    for i in range(1, layers):\n",
    "        # for all layers, activation function is ReLU\n",
    "        if i < layers-1:\n",
    "            act = 'relu'\n",
    "        # for final layer, activation function is softmax\n",
    "        else:\n",
    "            act = 'softmax'\n",
    "            \n",
    "        # adding the layers of NN\n",
    "        model.add(Dense(output_dim = nn_design[i], \n",
    "                    input_dim = nn_design[i-1],\n",
    "                    activation = act,\n",
    "                    kernel_regularizer = regularizers.l1_l2(l1 = L1, l2 = L2)))\n",
    "    \n",
    "    # compile model\n",
    "    opt = optimizers.adam(learning_rate = LEARNING_RATE)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])\n",
    "\n",
    "    # fit model\n",
    "    history = model.fit(train_X, train_y, epochs = EPOCHS, batch_size = BATCH_SIZE, \n",
    "          validation_data = (val_X, val_y),\n",
    "          # callbacks = [EarlyStopping(monitor='val_accuracy', patience=20)]\n",
    "          ) \n",
    "\n",
    "    # evaluate the model\n",
    "    _, test_acc = model.evaluate(test_X, test_y)\n",
    "    \n",
    "    train_cost = history.history['loss']\n",
    "    train_acc = history.history['accuracy']\n",
    "    val_cost = history.history['val_loss']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    return (train_cost, train_acc, val_cost, val_acc, test_acc)\n",
    "\n",
    "(trainX, valX, testX) = transform_dataset(StandardScaler(), nn_x_train, nn_x_validation, test_x)\n",
    "\n",
    "fig1, ax1 = plt.subplots(2,6, figsize = (40,20))\n",
    "fig2, ax2 = plt.subplots(2,6, figsize = (40,20))\n",
    "for i, design in enumerate(NN_DESIGNS):\n",
    "    fig1, ax1 = plt.subplots(1,2, figsize = (40,20))\n",
    "    print('Running design =', design)\n",
    "    \n",
    "    (train_cost, train_acc, val_cost, val_acc, test_acc) = evaluate_model(design, trainX, nn_y_train, valX, nn_y_validation, testX, test_y_01)\n",
    "    \n",
    "    ep = list(range(1,EPOCHS+1))\n",
    "     \n",
    "    ax1[i//5, i%5].plot(ep, train_cost, 'k:', label = 'Train')\n",
    "    ax1[i//5, i%5].plot(ep, val_cost, 'ko-', label = 'Val')\n",
    "    ax1[i//5, i%5].set_xlabel('EPOCH', fontsize = 20)\n",
    "    ax1[i//5, i%5].set_ylabel('cost', fontsize = 20)\n",
    "    ax1[i//5, i%5].set_title('Change in cost (design='+str(design)+')', fontsize = 25)\n",
    "    ax1[i//5, i%5].legend(fontsize = 20)\n",
    "    \n",
    "    ax2[i//5, i%5].plot(ep, train_acc, 'r:', label = 'Train')\n",
    "    ax2[i//5, i%5].plot(ep, val_acc, 'ro-', label = 'Val')\n",
    "    ax2[i//5, i%5].plot(ep, [test_acc]*len(ep), 'r-')\n",
    "    ax2[i//5, i%5].set_xlabel('EPOCH', fontsize = 20)\n",
    "    ax2[i//5, i%5].set_ylabel('accuracy', fontsize = 20)\n",
    "    ax2[i//5, i%5].set_ylim(0.4, 1)\n",
    "    ax2[i//5, i%5].set_title('Change in accuracy (design='+str(design)+')', fontsize = 25)\n",
    "    ax2[i//5, i%5].legend(fontsize = 20)\n",
    "    \n",
    "    fig1.show()\n",
    "    fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete variables that will no longer be used to allocate memory\n",
    "del train_cost\n",
    "del train_acc\n",
    "del val_cost\n",
    "del val_acc\n",
    "del test_acc\n",
    "del fig1\n",
    "del ax1\n",
    "del fig2\n",
    "del ax2\n",
    "del evaluate_model\n",
    "del trainX\n",
    "del valX\n",
    "del testX\n",
    "del NN_DESIGNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notes:\n",
    "\n",
    "1. As shown in this section, having more neurons does not necessarily equate to better results. I initially made the guess of using 1 hidden layer with 500 neurons due to the large number of input neurons. What ended up happening was that while the prediction accuracies were good in some cases, each run of the model took a really long time. Additionally this has often led to a lack of memory in my computer. In short, it is advisable to always start off experimenting with small number of neurons and hidden layers and build from there in order to save time and resources.\n",
    "\n",
    "2. Based on the experimentations in this subsection, it seems that having 2 hidden layers with 500 and 500 neurons respectively is the best way to move forward. The training and validation accuracies with this hidden layer architecture are higher than most of the other architectures (plus they run faster too).\n",
    "\n",
    "3. However, our job here isn't done. While we now have a model that predicts well (the Neural Network with the 16384 $\\rightarrow$ 500 $\\rightarrow$ 500 $\\rightarrow$ 2 architecture achieves 100\\% accuracy with more EPOCH training), our validation and test accuracies has not had much improvement. Hence, we will move on and experiment with the dropout regularization technique.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * #### Adding Dropout\n",
    " \n",
    " Since dropout in Neural Network is simply another type of regularizer, it may or may not be used along with the L1 and L2 regularizers. Therefore, in this section, we will experiment the training of our Neural Network model with 3 cases:\n",
    "    \n",
    "    1. Without dropout, but with the best L1, L2 regularization parameter pairing concluded from previous sections\n",
    "    \n",
    "    2. With dropout, but without any L1, L2 regularization\n",
    "    \n",
    "    3. With dropout, and with the best L1, L2 regularization parameter pairing concluded from previous sections\n",
    "    \n",
    " The code and results are shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting epochs, batch size, learning rate and L1, L2 regularization parameters\n",
    "EPOCHS = 50\n",
    "L1 = 0\n",
    "L2 = 1e-5\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "DESIGN = (INPUT_NODES, 500, OUTPUT_NODES)\n",
    "\n",
    "DROPOUT_L1L2_OPTIONS = [(False, True), (True, False), (True, True)] # (Dropout if True, L1/L2 regularized if True)\n",
    "\n",
    "def evaluate_model(nn_design, dropout, l1_l2, train_X, train_y, val_X, val_y, test_X, test_y):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    \n",
    "    layers = len(nn_design)\n",
    "    \n",
    "    for i in range(1, layers):\n",
    "        # for all layers, activation function is ReLU\n",
    "        if i < layers-1:\n",
    "            act = 'relu'\n",
    "        # for final layer, activation function is softmax\n",
    "        else:\n",
    "            act = 'softmax'\n",
    "            \n",
    "        # adding the layers of NN\n",
    "        if l1_l2:\n",
    "            model.add(Dense(output_dim = nn_design[i], \n",
    "                    input_dim = nn_design[i-1],\n",
    "                    activation = act,\n",
    "                    kernel_regularizer = regularizers.l1_l2(l1 = L1, l2 = L2)))\n",
    "        else:\n",
    "            model.add(Dense(output_dim = nn_design[i], \n",
    "                    input_dim = nn_design[i-1],\n",
    "                    activation = act)\n",
    "                      \n",
    "        if dropout:\n",
    "            model.add(Dropout(0.25))\n",
    "    \n",
    "    # compile model\n",
    "    opt = optimizers.adam(learning_rate = LEARNING_RATE)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])\n",
    "\n",
    "    # fit model\n",
    "    history = model.fit(train_X, train_y, epochs = EPOCHS, batch_size = BATCH_SIZE, \n",
    "          validation_data = (val_X, val_y),\n",
    "          # callbacks = [EarlyStopping(monitor='val_accuracy', patience=20)]\n",
    "          ) \n",
    "\n",
    "    # evaluate the model\n",
    "    _, test_acc = model.evaluate(test_X, test_y)\n",
    "    \n",
    "    train_cost = history.history['loss']\n",
    "    train_acc = history.history['accuracy']\n",
    "    val_cost = history.history['val_loss']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    return (train_cost, train_acc, val_cost, val_acc, test_acc)\n",
    "\n",
    "(trainX, valX, testX) = transform_dataset(StandardScaler(), nn_x_train, nn_x_validation, test_x)\n",
    "\n",
    "fig1, ax1 = plt.subplots(1,3, figsize = (40,20))\n",
    "fig2, ax2 = plt.subplots(1,3, figsize = (40,20))\n",
    "for i, (dropout, l1_l2) in enumerate(DROPOUT_L1l2_OPTIONS):\n",
    "    fig1, ax1 = plt.subplots(1,2, figsize = (40,20))\n",
    "    print('Running design =', design)\n",
    "    \n",
    "    (train_cost, train_acc, val_cost, val_acc, test_acc) = evaluate_model(DESIGN, dropout, l1_l2 trainX, nn_y_train, valX, nn_y_validation, testX, test_y_01)\n",
    "    \n",
    "    ep = list(range(1,EPOCHS+1))\n",
    "     \n",
    "    ax1[i].plot(ep, train_cost, 'k:', label = 'Train')\n",
    "    ax1[i].plot(ep, val_cost, 'ko-', label = 'Val')\n",
    "    ax1[i].set_xlabel('EPOCH', fontsize = 20)\n",
    "    ax1[i].set_ylabel('cost', fontsize = 20)\n",
    "    ax1[i].set_title('Change in cost (design='+str(design)+')', fontsize = 25)\n",
    "    ax1[i].legend(fontsize = 20)\n",
    "    \n",
    "    ax2[i].plot(ep, train_acc, 'r:', label = 'Train')\n",
    "    ax2[i].plot(ep, val_acc, 'ro-', label = 'Val')\n",
    "    ax2[i].plot(ep, [test_acc]*len(ep), 'r-')\n",
    "    ax2[i].set_xlabel('EPOCH', fontsize = 20)\n",
    "    ax2[i].set_ylabel('accuracy', fontsize = 20)\n",
    "    ax2[i].set_ylim(0.4, 1)\n",
    "    ax2[i].set_title('Change in accuracy (design='+str(design)+')', fontsize = 25)\n",
    "    ax2[i].legend(fontsize = 20)\n",
    "    \n",
    "    fig1.show()\n",
    "    fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete variables that will no longer be used to allocate memory\n",
    "del train_cost\n",
    "del train_acc\n",
    "del val_cost\n",
    "del val_acc\n",
    "del test_acc\n",
    "del fig1\n",
    "del ax1\n",
    "del fig2\n",
    "del ax2\n",
    "del evaluate_model\n",
    "del trainX\n",
    "del valX\n",
    "del testX\n",
    "del DROPOUT_L1L2_OPTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notes:\n",
    "\n",
    "Here we see that using the dropout technique did not really help us with our case, and therefore we will be sticking with our original model (ie. no dropout used)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Best(?) Possible Neural Network in Keras\n",
    "\n",
    "Using all the information obtain from the previous subsections, we attempt to construct and train the best possible Neural Network model to classify images of people who do and do not wear masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running NN\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import regularizers #for l1 or l2 regularizers\n",
    "from keras.callbacks import EarlyStopping #stop training when monitored argument stops decreasing/increasing\n",
    "\n",
    "EPOCHS = 300\n",
    "L1 = 0\n",
    "L2 = 1e-5\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "model = Sequential([\n",
    "    #input to first hidden layer\n",
    "    Dense(output_dim = LAYER1_NODES, input_dim = INPUT_NODES,\n",
    "          activation = 'relu',\n",
    "          kernel_regularizer = regularizers.l2(LAMBDA)\n",
    "          ),\n",
    "    \n",
    "    #first hidden layer to second hidden layer\n",
    "    Dense(output_dim = LAYER2_NODES, input_dim = LAYER1_NODES, \n",
    "          activation = 'relu',\n",
    "          kernel_regularizer = regularizers.l2(LAMBDA)\n",
    "          ),\n",
    "    \n",
    "    #second layer to third layer\n",
    "    Dense(output_dim = LAYER3_NODES, input_dim = LAYER2_NODES, \n",
    "          activation = 'relu',\n",
    "          kernel_regularizer = regularizers.l2(LAMBDA)\n",
    "          ),\n",
    "    \n",
    "    #third hidden layer to output\n",
    "    Dense(output_dim = OUTPUT_NODES, input_dim = LAYER2_NODES, activation = 'softmax'),\n",
    "    ])\n",
    "\n",
    "# compile models with the learning rates set\n",
    "opt = optimizers.adam(learning_rate = LEARNING_RATE)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(nn_x_train, nn_y_train, epochs = EPOCHS, batch_size = BATCH_SIZE, \n",
    "          validation_data = (nn_x_validation, nn_y_validation), verbose = 0,\n",
    "          callbacks = [EarlyStopping(monitor='val_accuracy', patience=30)]\n",
    "          ) \n",
    "\n",
    "#evaluate model on test set\n",
    "_, accuracy = model.evaluate(test_x, test_y_01)\n",
    "end = time.time()\n",
    "time_taken = end - start\n",
    "\n",
    "print('Test Data Accuracy:', '{:.3f}'.format(accuracy))\n",
    "print('Time taken:', round(time_taken,2), 'seconds')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# obtain predictions from model\n",
    "test_y_pred_01 = model.predict(test_x, verbose = 0)\n",
    "\n",
    "# convert the float values of test_y_pred_01 into a list of predictions 'Yes' or 'No'\n",
    "test_y_pred = []\n",
    "for i in range(len(test_y_pred_01)):\n",
    "    if test_y_pred_01[i][0] > test_y_pred_01[i][1]:\n",
    "        test_y_pred.append('Yes')\n",
    "    else:\n",
    "        test_y_pred.append('No')\n",
    "        \n",
    "# plot confusion matrix and record relevant data\n",
    "fig, ax = plt.subplots(1,2, figsize = (10,5))\n",
    "\n",
    "for i, normal in enumerate([None, 'true']):\n",
    "    confmat = confusion_matrix(test_y_true, test_y_pred, labels = ['Yes', 'No'], normalize = normal)\n",
    "    disp = ConfusionMatrixDisplay(confmat, display_labels = ['Yes', 'No'])\n",
    "    disp.plot(ax = ax[i], cmap = plt.cm.Blues)\n",
    "    if i == 0:\n",
    "        disp.ax_.set_title('Non-normalized Confusion Matrix')\n",
    "        classification_result['Neural Network'] = {'Time' : time_taken,\n",
    "                                     'True Positive' : confmat[0][0],\n",
    "                                     'True Negative' : confmat[1][1],\n",
    "                                     'False Positive' : confmat[1][0],\n",
    "                                     'False Negative' : confmat[0][1]}\n",
    "    else:\n",
    "        disp.ax_.set_title('Normalized Confusion Matrix')\n",
    "        disp.im_.set_clim(0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notes:\n",
    "\n",
    "For some reason, even after all the parameter tuning I have done, the resulting model still seems to be overfitting the data. It is possible that this model that I have trained is the best possible model and that it is impossible to train a Neural Network model that has a predictive value of more than 90\\% on the test data.\n",
    "\n",
    "However, as mentioned previously, there is almost an infinite amount of configurations and architecture designs in building a Neural Network model. It is more possible that there is a better hidden layer design, or better tuning of parameters that I have overlooked that can produce a model with a higher predictive value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time and Accuracy Comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following figure is used to compare the difference in error rate, false positive rate, false negative rate, and time of each of the used method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(classification_result, orient = 'index')\n",
    "df = df.reset_index()\n",
    "total_sum = df['True Positive'] + df['True Negative'] + df['False Negative'] + df['False Positive']\n",
    "df = df.assign(ErrorRate = (df['False Negative'] + df['False Positive']) / total_sum,\n",
    "              TP_rate = df['True Positive'] / (df['True Positive'] + df['False Negative']),\n",
    "              TN_rate = df['True Negative'] / (df['True Negative'] + df['False Positive']),\n",
    "              FP_rate = df['False Positive'] / (df['True Negative'] + df['False Positive']),\n",
    "              FN_rate = df['False Negative'] / (df['True Positive'] + df['False Negative']))\n",
    "df = df.rename(columns = {'index' : 'Method', 'ErrorRate' : 'Error %', 'TP_rate' : 'True Positive %',\n",
    "                         'TN_rate' : 'True Negative %', 'FP_rate' : 'False Positive %', 'FN_rate' : 'False Negative %'})\n",
    "df = df.sort_values('Error %', ascending = False)\n",
    "\n",
    "ind = np.arange(len(df))\n",
    "width = 0.3\n",
    "\n",
    "method = np.asarray(df['Method'])\n",
    "time_taken = np.asarray(df['Time'])\n",
    "fp = np.asarray(df['False Positive %'])\n",
    "fn = np.asarray(df['False Negative %'])\n",
    "err = np.asarray(df['Error %'])\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize = (20,10))\n",
    "ax1.bar(ind - width, err, width,color = 'yellow', edgecolor = 'black')\n",
    "ax1.bar(ind, fp, width, color = 'red', edgecolor = 'black')\n",
    "ax1.bar(ind + width, fn, width, color = 'green', edgecolor = 'black')\n",
    "ax1.legend(['Error Rate', 'False Positive Rate', 'False Negative Rate'], fontsize = 14)\n",
    "ax1.set_ylim(0,0.55)\n",
    "ax1.set_ylabel('Rate', fontsize = 14)\n",
    "ax1.set_yticklabels([0, 0.1, 0.2, 0.3, 0.4, 0.5], fontsize = 14)\n",
    "ax1.set_xticks(ind + width / 2)\n",
    "ax1.set_xticklabels(method, rotation = 20, fontsize = 14)\n",
    "ax1.set_title('Error and Time Analysis for Different ML Methods', fontsize = 18)\n",
    "\n",
    "for i in range(len(df)):\n",
    "    ax1.text(ind[i] - width, err[i] + 0.01, str(round(err[i], 3)), \n",
    "             ha = 'center', va = 'bottom', size = 14, rotation = 'vertical')\n",
    "    ax1.text(ind[i], fp[i] + 0.01, str(round(fp[i], 3)), \n",
    "             ha = 'center', va = 'bottom', size = 14, rotation = 'vertical')\n",
    "    ax1.text(ind[i] + width, fn[i] + 0.01, str(round(fn[i], 3)), \n",
    "             ha = 'center', va = 'bottom', size = 14, rotation = 'vertical')\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'blue'\n",
    "ax2.set_ylabel('Time', color=color, fontsize = 14)  # we already handled the x-label with ax1\n",
    "ax2.plot(method, time_taken, 'o-b')\n",
    "# ax2.set_ylim(0,1300)\n",
    "# ax2.set_yticklabels(list(range(0,1201,200)), fontsize = 14)\n",
    "ax2.tick_params(axis='y', labelcolor=color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References and Resources\n",
    "\n",
    "Plots:\n",
    "* https://stackoverflow.com/questions/61825227/plotting-multiple-confusion-matrix-side-by-side\n",
    "\n",
    "* https://matplotlib.org/3.1.1/gallery/subplots_axes_and_figures/figure_title.html\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html\n",
    "\n",
    "* https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\n",
    "\n",
    "* https://matplotlib.org/examples/api/barchart_demo.html\n",
    "\n",
    "SVM:\n",
    "* https://scikit-learn.org/stable/modules/svm.html\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing\n",
    "\n",
    "* https://stats.stackexchange.com/questions/18030/how-to-select-kernel-for-svm\n",
    "\n",
    "* https://towardsdatascience.com/a-guide-to-svm-parameter-tuning-8bfe6b8a452c\n",
    "\n",
    "* https://towardsdatascience.com/the-kernel-trick-c98cdbcaeb3f#:~:text=The%20%E2%80%9Ctrick%E2%80%9D%20is%20that%20kernel,the%20data%20by%20these%20transformed\n",
    "\n",
    "* http://www.cs.cmu.edu/~aarti/Class/10601/slides/svm_11_22_2011.pdf\n",
    "\n",
    "Logistic Regression:\n",
    "* https://realpython.com/logistic-regression-python/\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "* https://www.knime.com/blog/regularization-for-logistic-regression-l1-l2-gauss-or-laplace#:~:text=Regularization%20for%20Logistic%20Regression%3A%20L1%2C%20L2%2C%20Gauss%20or%20Laplace%3F,-Mon%2C%2003%2F12&text=Regularization%20can%20be%20used%20to%20avoid%20overfitting.&text=In%20other%20words%3A%20regularization%20can,from%20overfitting%20the%20training%20dataset\n",
    "\n",
    "* https://stackoverflow.com/questions/22851316/what-is-the-inverse-of-regularization-strength-in-logistic-regression-how-shoul\n",
    "\n",
    "LDA:\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html\n",
    "\n",
    "Logistic Regression vs LDA:\n",
    "* https://stats.stackexchange.com/questions/95247/logistic-regression-vs-lda-as-two-class-classifiers\n",
    "\n",
    "Random Forest\n",
    "* https://www.datacamp.com/community/tutorials/random-forests-classifier-python\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "* https://towardsdatascience.com/an-implementation-and-explanation-of-the-random-forest-in-python-77bf308a9b76\n",
    "\n",
    "* https://en.wikipedia.org/wiki/Decision_tree_learning\n",
    "\n",
    "* https://towardsdatascience.com/how-to-visualize-a-decision-tree-from-a-random-forest-in-python-using-scikit-learn-38ad2d75f21c\n",
    "\n",
    "Neural Network:\n",
    "* https://adventuresinmachinelearning.com/python-tensorflow-tutorial/\n",
    "\n",
    "* https://adventuresinmachinelearning.com/improve-neural-networks-part-1/\n",
    "\n",
    "* https://www.ritchieng.com/machine-learning/deep-learning/tensorflow/regularization/\n",
    "\n",
    "* https://en.wikipedia.org/wiki/Backpropagation\n",
    "\n",
    "* https://machinelearningmastery.com/early-stopping-to-avoid-overtraining-neural-network-models/\n",
    "\n",
    "* https://www.kdnuggets.com/2019/12/5-techniques-prevent-overfitting-neural-networks.html\n",
    "\n",
    "* https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw#:~:text=The%20number%20of%20hidden%20neurons,size%20of%20the%20input%20layer\n",
    "\n",
    "* https://towardsdatascience.com/pruning-deep-neural-network-56cae1ec5505\n",
    "\n",
    "* https://towardsdatascience.com/how-to-train-neural-network-faster-with-optimizers-d297730b3713\n",
    "\n",
    "* https://stats.stackexchange.com/questions/345990/why-does-the-loss-accuracy-fluctuate-during-the-training-keras-lstm\n",
    "\n",
    "* https://stats.stackexchange.com/questions/255105/why-is-the-validation-accuracy-fluctuating\n",
    "\n",
    "* https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/\n",
    "\n",
    "* https://stackoverflow.com/questions/45587378/how-to-get-predicted-values-in-keras\n",
    "\n",
    "* https://www.analyticsvidhya.com/blog/2018/04/fundamentals-deep-learning-regularization-techniques/\n",
    "\n",
    "* http://theorangeduck.com/page/neural-network-not-working\n",
    "\n",
    "* https://machinelearningmastery.com/how-to-improve-neural-network-stability-and-modeling-performance-with-data-scaling/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
